{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "–£–±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º (–Ω–æ –Ω–µ –Ω–∞ –∫–∞–±–∞—Ä–¥–∏–Ω—Å–∫–æ–º/–∞–¥—ã–≥–µ–π—Å–∫–æ–º) —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–æ–∫ (–ª–∞–Ω–≥–¥–µ—Ç–µ–∫—Ç —Ç—É—Ç –Ω–µ –ø–æ–º–æ–∂–µ—Ç), –ø—Ä–∏ —ç—Ç–æ–º —Ä–∏–º—Å–∫–∏–µ —Ü–∏—Ñ—Ä—ã –æ—Å—Ç–∞–≤–ª—è–µ–º"
      ],
      "metadata": {
        "id": "9hJRTfVv_7qG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hrIBJO9gprTx",
        "outputId": "ba359c9d-51d8-411f-9e94-60b88cb883bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordfreq\n",
            "  Downloading wordfreq-3.1.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ftfy>=6.1 (from wordfreq)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting langcodes>=3.0 (from wordfreq)\n",
            "  Downloading langcodes-3.5.1-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting locate<2.0.0,>=1.1.1 (from wordfreq)\n",
            "  Downloading locate-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (1.1.2)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from wordfreq) (2025.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy>=6.1->wordfreq) (0.4.0)\n",
            "Downloading wordfreq-3.1.1-py3-none-any.whl (56.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.1-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m183.1/183.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading locate-1.1.1-py3-none-any.whl (5.4 kB)\n",
            "Installing collected packages: locate, langcodes, ftfy, wordfreq\n",
            "Successfully installed ftfy-6.3.1 langcodes-3.5.1 locate-1.1.1 wordfreq-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install wordfreq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from wordfreq import zipf_frequency\n",
        "import unicodedata\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "cKS4IDCCALLt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMjV9s1sJ1dt",
        "outputId": "55e03906-4eef-49c3-e260-1c5be9622e60"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_FILE = \"/content/drive/MyDrive/Adyghe_no_ocr_NFD.txt\"\n",
        "CLEAN_FILE = \"/content/drive/MyDrive/Adyghe_clean_no_ru_long.txt\"\n",
        "REMOVED_FILE = \"/content/drive/MyDrive/Adyghe_removed_ru_words.tsv\"\n",
        "\n",
        "with open(INPUT_FILE, encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "text = unicodedata.normalize(\"NFC\", text)\n",
        "\n",
        "STICKS = set(\"I\")\n",
        "HYPHENS = \"-‚Äì‚Äî‚àí\"\n",
        "ZIPF_THRESHOLD = 3.0\n",
        "\n",
        "WORD_RE = re.compile(\n",
        "    rf\"[–∞-—è—ë”Ä”èIi‚Ö†‚Öº|1{HYPHENS}]+\",\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "removed_counter = Counter()\n",
        "\n",
        "# ====== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø re.sub ======\n",
        "ZIPF_THRESHOLD = 3.0\n",
        "\n",
        "def process_match(match):\n",
        "    word = match.group(0)\n",
        "    w = word.lower()\n",
        "\n",
        "    # –µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–ª–æ—á–∫–∞ ‚Üí NON-RU\n",
        "    if any(ch in STICKS for ch in word):\n",
        "        return word\n",
        "\n",
        "    freq = zipf_frequency(w, \"ru\")\n",
        "\n",
        "    # —É–¥–∞–ª—è–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ —Ä—É—Å—Å–∫–æ–µ\n",
        "    if freq >= ZIPF_THRESHOLD and len(w) > 3:\n",
        "        removed_counter[w] += 1\n",
        "        return \"\"\n",
        "    else:\n",
        "        return word\n",
        "\n",
        "# ====== –û–ë–†–ê–ë–û–¢–ö–ê –¢–ï–ö–°–¢–ê ======\n",
        "clean_text = WORD_RE.sub(process_match, text)\n",
        "\n",
        "# ====== –°–û–•–†–ê–ù–ï–ù–ò–ï ======\n",
        "with open(CLEAN_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(clean_text)\n",
        "\n",
        "with open(REMOVED_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"word\\tcount\\tzipf_frequency\\n\")\n",
        "    for w, cnt in removed_counter.most_common():\n",
        "        freq = zipf_frequency(w, \"ru\")\n",
        "        f.write(f\"{w}\\t{cnt}\\t{freq:.2f}\\n\")\n",
        "\n",
        "print(\"–û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω:\", CLEAN_FILE)\n",
        "print(\"–£–¥–∞–ª—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:\", REMOVED_FILE)\n",
        "print(\"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤:\", len(removed_counter))\n",
        "print(\"–í—Å–µ–≥–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –≤—Ö–æ–∂–¥–µ–Ω–∏–π:\", sum(removed_counter.values()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhuMZSViIl6C",
        "outputId": "f71f84bf-0010-48d8-863d-fff5276c4264"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: /content/drive/MyDrive/Adyghe_clean_no_ru_long.txt\n",
            "–£–¥–∞–ª—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: /content/drive/MyDrive/Adyghe_removed_ru_words.tsv\n",
            "–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤: 20244\n",
            "–í—Å–µ–≥–æ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –≤—Ö–æ–∂–¥–µ–Ω–∏–π: 302621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"
      ],
      "metadata": {
        "id": "dSJHClNkJSq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = 0\n",
        "ru_words = 0\n",
        "\n",
        "for match in WORD_RE.finditer(text):\n",
        "    word = match.group(0)\n",
        "    w = word.lower()\n",
        "    total_words += 1\n",
        "\n",
        "    if any(ch in STICKS for ch in word):\n",
        "        continue\n",
        "\n",
        "    freq = zipf_frequency(w, \"ru\")\n",
        "\n",
        "    if freq >= ZIPF_THRESHOLD and len(w) > 3:\n",
        "        ru_words += 1\n",
        "\n",
        "percent_ru = ru_words / total_words * 100 if total_words else 0\n",
        "\n",
        "print(\"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê\")\n",
        "print(\"–í—Å–µ–≥–æ —Å–ª–æ–≤:\", total_words)\n",
        "print(\"–†—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤:\", ru_words)\n",
        "print(f\"–ü—Ä–æ—Ü–µ–Ω—Ç —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {percent_ru:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NhfG_bwJUua",
        "outputId": "175425d5-f891-4cc8-9deb-96e1b0cca94f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê\n",
            "–í—Å–µ–≥–æ —Å–ª–æ–≤: 11329083\n",
            "–†—É—Å—Å–∫–∏—Ö —Å–ª–æ–≤: 302621\n",
            "–ü—Ä–æ—Ü–µ–Ω—Ç —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: 2.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–∏–º–µ—Ä –Ω–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ"
      ],
      "metadata": {
        "id": "0eU-NmaAPOYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–î–∞–≥–¥–∏–∑–µ–ª—å¬ª\n",
        "04.09 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ö–∞–≤–∫–∞–∑—Ç—Ä–∞–Ω—Å–≥–∞–∑¬ª\n",
        "18.09 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê—Å—Ç—Ä–∞—Ö–∞–Ω—å¬ª\n",
        "02.10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–¢–æ—Ä–ø–µ–¥–æ¬ª\n",
        "16.10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê–ª–∞–Ω–∏—è-–î¬ª\n",
        "30.10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–î–∏–Ω–∞–º–æ¬ª\n",
        "25.04 - –±—ç—Ä—ç—Å–∫—ç–∂—ä—ã–π\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê–Ω–≥—É—à—Ç¬ª\n",
        "13.05 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
        "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–†–æ—Ç–æ—Ä¬ª\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "j4tMmAI-Qmqs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== –ù–ê–°–¢–†–û–ô–ö–ò ======\n",
        "RU_SENT_THRESHOLD = 0.7\n",
        "MIN_WORDS_IN_SENT = 3\n",
        "\n",
        "STICKS = set(\"”Ä”èIi‚Ö†‚Öº|1\")\n",
        "HYPHENS = \"-‚Äì‚Äî‚àí\"\n",
        "\n",
        "# ====== –†–ï–ì–£–õ–Ø–†–ö–ò ======\n",
        "WORD_RE = re.compile(\n",
        "    rf\"(?:\\p{{Cyrillic}}|\\p{{Mn}}|\\p{{Nd}}|[Ii‚Ö†‚Öº|1]|[{HYPHENS}])+\",\n",
        "    re.IGNORECASE\n",
        ")\n",
        "\n",
        "SENT_RE = re.compile(r\"[^.!?]+[.!?]?\", re.DOTALL)\n",
        "\n",
        "# ====== –§–£–ù–ö–¶–ò–ò ======\n",
        "def letter_len_nfd(word):\n",
        "    return sum(\n",
        "        1 for ch in word\n",
        "        if unicodedata.category(ch).startswith(\"L\")\n",
        "    )\n",
        "\n",
        "def has_stick(word):\n",
        "    return any(ch in STICKS for ch in word)\n",
        "\n",
        "def classify_word(word):\n",
        "    \"\"\"\n",
        "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
        "    - \"RU\"\n",
        "    - \"NON-RU\"\n",
        "    - \"SKIP\"  (–µ—Å–ª–∏ –¥–ª–∏–Ω–∞ <= 3)\n",
        "    \"\"\"\n",
        "    if has_stick(word):\n",
        "        return \"NON-RU\", 0.0\n",
        "\n",
        "    length = letter_len_nfd(word)\n",
        "    if length <= 3:\n",
        "        return \"SKIP\", 0.0\n",
        "\n",
        "    word_nfc = unicodedata.normalize(\"NFC\", word)\n",
        "    freq = zipf_frequency(word_nfc.lower(), \"ru\")\n",
        "\n",
        "    if freq > 0:\n",
        "        return \"RU\", freq\n",
        "    return \"NON-RU\", 0.0\n",
        "\n",
        "def is_ru_sentence(sent):\n",
        "    words = WORD_RE.findall(sent)\n",
        "\n",
        "    ru = 0\n",
        "    considered = 0\n",
        "\n",
        "    for w in words:\n",
        "        label, _ = classify_word(w)\n",
        "\n",
        "        if label == \"SKIP\":\n",
        "            continue  # —Å–ª–æ–≤–∞ ‚â§3 –±—É–∫–≤ –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ–º\n",
        "\n",
        "        considered += 1\n",
        "        if label == \"RU\":\n",
        "            ru += 1\n",
        "\n",
        "    if considered < MIN_WORDS_IN_SENT:\n",
        "        return False\n",
        "\n",
        "    return (ru / considered) >= RU_SENT_THRESHOLD\n",
        "\n",
        "# ====== –û–ë–†–ê–ë–û–¢–ö–ê ======\n",
        "print(\"=== –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –°–õ–û–í ===\\n\")\n",
        "\n",
        "for w in WORD_RE.findall(text):\n",
        "    label, freq = classify_word(w)\n",
        "    print(f\"{w:<15} {label:<7} {freq:.2f}\")\n",
        "\n",
        "print(\"\\n=== –ü–†–û–í–ï–†–ö–ê –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ô ===\\n\")\n",
        "\n",
        "kept = []\n",
        "removed = []\n",
        "\n",
        "for sent in SENT_RE.findall(text):\n",
        "    if is_ru_sentence(sent):\n",
        "        removed.append(sent)\n",
        "        print(\"[–£–î–ê–õ–ï–ù–û]\", sent.strip())\n",
        "    else:\n",
        "        kept.append(sent)\n",
        "        print(\"[–û–°–¢–ê–õ–û–°–¨]\", sent.strip())\n",
        "\n",
        "print(\"\\n=== –ò–¢–û–ì–û–í–´–ô –¢–ï–ö–°–¢ ===\\n\")\n",
        "print(\"\".join(kept))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHG8ZUJnQJA7",
        "outputId": "a12131f1-1d79-4495-d1fb-aa075df52f82"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –°–õ–û–í ===\n",
            "\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–î–∞–≥–¥–∏–∑–µ–ª—å       RU      1.63\n",
            "04              SKIP    0.00\n",
            "09              SKIP    0.00\n",
            "-               SKIP    0.00\n",
            "—Ç—Ö—å–∞—É–º–∞—Ñ        NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–ö–∞–≤–∫–∞–∑—Ç—Ä–∞–Ω—Å–≥–∞–∑  NON-RU  0.00\n",
            "18              NON-RU  0.00\n",
            "09              SKIP    0.00\n",
            "-               SKIP    0.00\n",
            "—Ç—Ö—å–∞—É–º–∞—Ñ        NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–ê—Å—Ç—Ä–∞—Ö–∞–Ω—å       RU      3.71\n",
            "02              SKIP    0.00\n",
            "10              NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "—Ç—Ö—å–∞—É–º–∞—Ñ        NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–¢–æ—Ä–ø–µ–¥–æ         RU      4.12\n",
            "16              NON-RU  0.00\n",
            "10              NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "—Ç—Ö—å–∞—É–º–∞—Ñ        NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–ê–ª–∞–Ω–∏—è-–î        RU      3.37\n",
            "30              SKIP    0.00\n",
            "10              NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "—Ç—Ö—å–∞—É–º–∞—Ñ        NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–î–∏–Ω–∞–º–æ          RU      4.79\n",
            "25              SKIP    0.00\n",
            "04              SKIP    0.00\n",
            "-               SKIP    0.00\n",
            "–±—ç—Ä—ç—Å–∫—ç–∂—ä—ã–π     NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–ê–Ω–≥—É—à—Ç          RU      2.34\n",
            "13              NON-RU  0.00\n",
            "05              SKIP    0.00\n",
            "-               SKIP    0.00\n",
            "—Ç—Ö—å–∞—É–º–∞—Ñ        NON-RU  0.00\n",
            "–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä      NON-RU  0.00\n",
            "-               SKIP    0.00\n",
            "–†–æ—Ç–æ—Ä           RU      3.34\n",
            "\n",
            "=== –ü–†–û–í–ï–†–ö–ê –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ô ===\n",
            "\n",
            "[–û–°–¢–ê–õ–û–°–¨] ¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–î–∞–≥–¥–∏–∑–µ–ª—å¬ª\n",
            "04.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 09 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ö–∞–≤–∫–∞–∑—Ç—Ä–∞–Ω—Å–≥–∞–∑¬ª\n",
            "18.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 09 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê—Å—Ç—Ä–∞—Ö–∞–Ω—å¬ª\n",
            "02.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–¢–æ—Ä–ø–µ–¥–æ¬ª\n",
            "16.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê–ª–∞–Ω–∏—è-–î¬ª\n",
            "30.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–î–∏–Ω–∞–º–æ¬ª\n",
            "25.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 04 - –±—ç—Ä—ç—Å–∫—ç–∂—ä—ã–π\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê–Ω–≥—É—à—Ç¬ª\n",
            "13.\n",
            "[–û–°–¢–ê–õ–û–°–¨] 05 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–†–æ—Ç–æ—Ä¬ª\n",
            "\n",
            "=== –ò–¢–û–ì–û–í–´–ô –¢–ï–ö–°–¢ ===\n",
            "\n",
            "\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–î–∞–≥–¥–∏–∑–µ–ª—å¬ª\n",
            "04.09 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ö–∞–≤–∫–∞–∑—Ç—Ä–∞–Ω—Å–≥–∞–∑¬ª\n",
            "18.09 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê—Å—Ç—Ä–∞—Ö–∞–Ω—å¬ª\n",
            "02.10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–¢–æ—Ä–ø–µ–¥–æ¬ª\n",
            "16.10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê–ª–∞–Ω–∏—è-–î¬ª\n",
            "30.10 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–î–∏–Ω–∞–º–æ¬ª\n",
            "25.04 - –±—ç—Ä—ç—Å–∫—ç–∂—ä—ã–π\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–ê–Ω–≥—É—à—Ç¬ª\n",
            "13.05 - —Ç—Ö—å–∞—É–º–∞—Ñ\n",
            "¬´–ó—ç–∫—ä–æ—à–Ω—ã–≥—ä¬ª - ¬´–†–æ—Ç–æ—Ä¬ª\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_39JUVPUEG6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}